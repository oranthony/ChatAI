{
  "models": 
  [
    {
      "name" : "BlenderBot",
      "author": "Facebook",
      "dataSize": "400M",
      "description": [
         "The Blender chatbot model (BlenderBot 1.0) was first proposed in the paper, Recipes for building an open-domain chatbot on 30th April 2020. This is a deep learning model that has been trained to interact and respond like a conversational agent."
        ,
        "The latest release is the BlenderBot 2.0. The model uses a standard seq2seq model transformer-based architecture to generate responses. This architecture uses Transformers as its base, initially proposed in a paper by Google’s research team."
      ],
      "link": "https://huggingface.co/facebook/blenderbot-400M-distill"
    },
    {
      "name" : "BlenderBot 3B",
      "author": "Facebook",
      "dataSize": "3B",
      "description": [
         "The Blender chatbot model (BlenderBot 1.0) was first proposed in the paper, Recipes for building an open-domain chatbot on 30th April 2020. This is a deep learning model that has been trained to interact and respond like a conversational agent."
        ,
        "The latest release is the BlenderBot 2.0. The model uses a standard seq2seq model transformer-based architecture to generate responses. This architecture uses Transformers as its base, initially proposed in a paper by Google’s research team.",
        "This is the same model as BlenderBot except it has been trained on a bigger data set."
      ],
      "link": "https://huggingface.co/facebook/blenderbot-3B"
    },
    {
      "name" : "DialoGPT",
      "author": "Microsoft",
      "dataSize": "147M",
      "description": [
         "DialoGPT is a SOTA large-scale pretrained dialogue response generation model for multiturn conversations. The human evaluation results indicate that the response generated from DialoGPT is comparable to human response quality under a single-turn conversation Turing test. "
        ,
        " The model is trained on 147M multi-turn dialogue from Reddit discussion thread."
        
      ],
      "link": "https://huggingface.co/microsoft/DialoGPT-large"
    },
    {
      "name" : "openjourney",
      "author": "PromptHero",
      "dataSize": "123M",
      "description": [
         "Openjourney is a custom text-to-image model that generates AI art images in the style of Midjourney. It's a fine-tune of Stable Diffusion.",
         "Openjourney is the second most downloaded text-to-image model on HuggingFace, only after Stable Diffusion itself. It's been downloaded millions of times, and it's also one of the top models on Replicate, with several million runs."
      ],
      "link": "https://huggingface.co/prompthero/openjourney"
    },
    {
      "name" : "Stable Diffusion XL",
      "author": "Stability AI",
      "dataSize": "6.6B",
      "description": [
         "SDXL consists of an ensemble of experts pipeline for latent diffusion: In a first step, the base model is used to generate (noisy) latents, which are then further processed with a refinement model specialized for the final denoising steps."
      ],
      "link": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
    },
    {
      "name" : "Stable Diffusion 1.5",
      "author": "Robin Rombach, Patrick Esser",
      "dataSize": "1B",
      "description": [
         "Stable Diffusion is a latent text-to-image diffusion model capable of generating photo-realistic images given any text input. ",
         "The Stable-Diffusion-v1-5 checkpoint was initialized with the weights of the Stable-Diffusion-v1-2 checkpoint and subsequently fine-tuned on 595k steps at resolution 512x512 on laion-aesthetics v2 5+ and 10% dropping of the text-conditioning to improve classifier-free guidance sampling."
      ],
      "link": "https://huggingface.co/runwayml/stable-diffusion-v1-5"
    }
  ]
}